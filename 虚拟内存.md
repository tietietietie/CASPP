# 虚拟内存：概念

## 地址空间

### 两种不同系统

有一些系统如汽车，电梯内的控制设备，系统较简单，使用的是直接物理地址，CPU访问内存（main memory）时直接使用物理地址（physical address,PA),如下图所示：

![image-20200308123107014](虚拟内存.assets/image-20200308123107014.png)

服务器或者电脑上的系统，CPU访问内存时，使用的是虚拟地址（virtual address,VA），把VA发送给MMU（内存管理单元），进行地址转换（address translation），生成了PA，在从内存中取数据，发送给CPU。

![image-20200308123123469](虚拟内存.assets/image-20200308123123469.png)

### 地址空间术语

1. 地址空间：整数地址的集合
2. 线性地址空间：连续的非负整数地址集合
3. 虚拟地址空间：大小为2^n的连续地址空间
4. 物理地址空间：大小为2^m的连续地址空间

一般来说，n>m

### 为什么要使用虚拟内存？

每次访问内存，都需要经过MMU来转换，这样难道不会降低效率吗？首先理解虚拟化：

**虚拟化**是指拦截对某个资源的访问权限，提供对资源的抽象，对用户展现不同视图，比如磁盘，通过磁盘管理器的虚拟化，CPU看到的只是连续的逻辑块，而不是磁盘，磁道这些物理设备，对磁盘的读写操作，被磁盘管理器拦截。

使用虚拟内存的优点

1. 能够更有效率的使用DRAM（因为DRAM也就是主存，称为了VM的cache）
2. 能够简化内存管理（每个进程都有相似的连续地址空间）
3. 能够帮助我们分离地址空间，实现数据保护（不同进程的虚拟内存是不一样的，用户程序不能访问内核的代码和数据）

## 虚拟内存作为缓存的工具

### 虚拟内存和物理内存

VM：长度为N的连续地址，存在磁盘上

PM：作为VM的缓存，存在DRAM上

![image-20200308124736389](虚拟内存.assets/image-20200308124736389.png)

可以发现：

VM被很多块，被称为页面（pages），其中VM中的称为虚拟页面VP，被缓存在PM中的块称为物理页面，PP。

页面的大小为2^p，通常比之前学到的缓存块大。（4096个字节，4kB）

同时VM上还有一些页面是空的，称为未分配(unallocated)，也有些分配了但是没被缓存的（uncached）。

### DRAM缓存

DRAM作为缓存，会有很严重的未命中惩罚，因为从磁盘取数据非常慢，所以我们采取以下措施，来提高命中率

1. 使用大的cache block，称为页面（4KB/4MB）
2. 完全关联性：任何的VP都有可能放在任何的PP，而不是像缓存那样有限制（需要map function）
3. 非常复杂的替换算法：为了尽量减少未命中，不能简单的使用缓存那样的LCU算法（而且是在软件级实现）
4. 不能使用直接写(write through)，使用回写（write back）

### 页表

页表是由页表项组成（page table entries（PET））组成，每一个页表项都对应着一个（VM,PM）对（有效位为1时）

#### 页表命中

当CPU所需的虚拟地址在页表中能找到对应的PET，此时便可在DRAM中找到对应物理地址，从而page hit!

![image-20200308130711869](虚拟内存.assets/image-20200308130711869.png)

#### 页缺失

当CPU所需要的页面没有存放在DRAM中，发生了DRAM cache miss，如下图所示，当CPU要访问VP3时，有效位是0，此时会发生页缺失异常（page fault exception），控制权交给kernal的handler，handler选出DRAM中要被替换的PP（存在DRAM的VP）（此处选择VP4），然后PP3存放着VP3的数据，而VP4的PTE有效位为0，指向的是VM（也就是DISK）

![image-20200309092222888](虚拟内存.assets/image-20200309092222888.png)

![image-20200309092328370](虚拟内存.assets/image-20200309092328370.png)

#### 页面分配

原本未分配的页面如VP5，给他分配磁盘空间（如使用malloc），此空间会指向disk，而不是DRAM！！

![image-20200309092521255](虚拟内存.assets/image-20200309092521255.png)

#### 局部性保证了虚拟内存性能！

虚拟内存看上去会花费很多时间（每次都要查找PTE，还会引发demanding page），但是由于程序的局部性，程序总是趋向于访问一个**较小的活动虚拟页面，称为工作集**，当工作集比主存小时，此进程会有很好的性能。但是当所有进程工作集的大小比主存大时，可能会出现抖动（thrashing）（经常出现page falut exception）

## 虚拟内存作为内存管理的工具

* 每个进程都有自己的虚拟内存，从而每个进程都把内存空间看做时连续的线性序列。

![image-20200309093224111](虚拟内存.assets/image-20200309093224111.png)

* 虚拟内存能够简化内存的分配：因为任何的VP都能匹配（map）到任何的PP，而且VP在不同的时刻可以在不同的PP内。
* 还能够实现多进程间数据共享，如上图的PP6（可能为lib.c），不需要复制，所有进程都能得到一份PP6内容的副本。
* 能够简化“链接”和“加载”过程
  * 链接过程变得容易：因为所有的虚拟内存空间都在相同的地方开始（地址空间相同）
  * 加载过程：让当前进程的PTEs无效（invalid），然后按需将新程序的.text和.data部分一页页地复制到当前进程地page table，从而实现当前进程能执行不同地程序。

![image-20200309094038408](虚拟内存.assets/image-20200309094038408.png)

## 虚拟内存作为内存保护的工具

PTE的每个条目之前都有一个“权限位”，说明目标PP是可读/可写/可执行等等。其中sup表示是内核程序还是用户程序。

![image-20200309094500875](虚拟内存.assets/image-20200309094500875.png)



## 地址转换

### 常用术语

虚拟地址空间V；物理地址空间P，地址转换MAP(a) = a'（由虚拟地址a转换位物理地址a'）

基本参数：

* N：虚拟地址空间号
* M：物理地址空间号
* P：页大小
* VA组成：
  * TLB：
  * TLBT
  * VPN：虚拟页面号
  * VPO：虚拟页面偏移量
* PA组成：
  * PPN：物理页面号
  * PPO：物理页面偏移量

### 利用page table进行地址转换

首先，当前进程有一个页面表指针存放在CR3这个寄存器中，用于页面表表项的查找，根据VPN，可以在页面表中查找到PPN（如果没有page fault的话)，而PPO和VPO是相同的，因为页面大小是相同的。

而且，偏移量位数位P，因为页面大小最多位P位**，当偏移量超过P，会在VPN中增加一位**，表示进入了下一个页面。

![image-20200309101000340](虚拟内存.assets/image-20200309101000340.png)

### 地址转换过程：page hit

可以发现PTE其实存在于主存或者缓存中，MMU先从主存或者缓存得到表项，然后计算出物理地址PA，再命令主存或者缓存将目标地址的数据发送给CPU。

![image-20200309101317379](虚拟内存.assets/image-20200309101317379.png)

### 地址转换过程：page fault

MMU得到的PTE发现有效位是0，引发了exception，挑选出victim（可能会回写），然后把需要的VP传到选好的PP，更新PTE，然后**从新执行**那条指令

![image-20200309101647171](虚拟内存.assets/image-20200309101647171.png)

### 地址转换过程：缓存的作用

![image-20200309101754460](虚拟内存.assets/image-20200309101754460.png)

可以发现：缓存只是主存的子集而已。

### 使用TLB加速地址转换

PTE条目存放在缓存中，存在着缓存未命中风险，就算缓存命中，也就很小的L1级缓存延迟，为了加速对PTE的访问时间，MMU内部有一个硬件级的缓存，存放着最近访问的PTE条目，称为TLB（translation lookaside buffer)

和访问主存的page table类似，也是使用VA的VPN作为索引来访问TLB，其中VPN分成了两部分，TLBI用于访问set，TLBT用于访问set中的某一列（跟普通的缓存一样的机制，也是**硬件级的搜索**）

![image-20200309111519273](虚拟内存.assets/image-20200309111519273.png)

#### TLB命中

![image-20200309111620409](虚拟内存.assets/image-20200309111620409.png)

可以发现：TLB命中时，减少了对内存的访问。

#### TLB未命中

![image-20200309111653013](虚拟内存.assets/image-20200309111653013.png)

可以发现：TLB未命中和普通的在内存中查找PTE类似，只是会把未命中PTE在TLB中更新。

### page table存储

假设页大小为4k，也就是2^12 bytes，64位系统一个可用地址为2^48，假设每个地址需要一个8 bytes的PTE存储，则一共需要2^48 / 2^12 *2^3 = 2^39 bytes，也就是512G来存储页表，这显然是不现实的，因为**绝大部分的VM都没有使用**，而不需要为这些没有使用的地址分配PTE。

解决办法：采用多级页表

![image-20200309112235318](虚拟内存.assets/image-20200309112235318.png)

如上所示：存储一个VM，最终只用到了一个一级页表和3个二级页表，每个页表很小（4KB）。

**使用多级页表时，MMU如何找到所需的PTE呢？**

把VP中的VPN分成K等分，每一等分都可以帮助我们在第i级页表中找到下一级页表的**头指针**，最后一级页表，存的为所需的PTE，如下所示：

![image-20200309112612756](虚拟内存.assets/image-20200309112612756.png)

系统用几级页表，由硬件确定，intel好像用的是4级。



# 虚拟内存：系统

## 简单系统中实现地址转换

### 前提条件

VA：14位，PA：12位，page size：64字节，也就是6位

如下图所示：

![image-20200310112705831](虚拟内存.assets/image-20200310112705831.png)

TLB：16个条目，4-way

![image-20200310112829833](虚拟内存.assets/image-20200310112829833.png)

page table：

![image-20200310112859044](虚拟内存.assets/image-20200310112859044.png)

cache：16个set，直接匹配（没有Line），每个block 四个字节，所以有两位存储block offset(co)

![image-20200310113135322](虚拟内存.assets/image-20200310113135322.png)

### 地址转换举例

![image-20200310113213345](虚拟内存.assets/image-20200310113213345.png)

如图：MMU得到VA后，再TLB中利用VPN找到了对应的的PTE，从而得到的PPN，发送给内存（cache），cache根据PA，找到了对应的数据为0x36。如何找缓存的数据（根据CT：tag：确定是否存在，以及在哪列，CI：set：确定set，CO：确定block的偏移量）

![image-20200310113732675](虚拟内存.assets/image-20200310113732675.png)

上图的VA没有在TLB中找到PTE，但是在Page table中找到了PTE，从而确定了PPN，得到PA，根据PA发生了cache miss，接着在主存中寻找。



## 举例：core i7/Linux的内存结构

### i7的物理内存结构

![image-20200310114022177](虚拟内存.assets/image-20200310114022177.png)

注意的点：1，L1级缓存分为指令缓存和数据缓存。2，L1级缓存的大小收到限制，因为VPO = PPO = CI + CO，一般CO是有限制的，VPO也是有限制的，所以set数量有限制，从而缓存大小有限制。

### 地址转换过程

![image-20200310114259402](虚拟内存.assets/image-20200310114259402.png)

可以发现：

1，VA中的VPO = PPO = CI+CO：所有在转换过程中，可以先把VPO传给缓存L1，缓存根据CI找出对应的set，以及读取8个tag，MMU转换完VPN输出PPN后，得到Tag与8个tag比较。（virtual indexed, physically tagged)(需要仔细设置缓存大小)

2，得到的数据（result）是32位或者64位的。

3，PPN竟然比VPN大。

### PTE图解

![image-20200310114918549](虚拟内存.assets/image-20200310114918549.png)

可以发现：MMU规定了每个页面（或子页表）的权限（读些/内核等等），其中page table physical base address：为下一个子页表的起始地址或者物理地址（最重要，40位）

MMU的地址转换过程如下所示：

![image-20200310115227382](虚拟内存.assets/image-20200310115227382.png)

其中：CR3存放的是第一级页表的起始地址，接着，根据VPN分段，可以一级级的查找到所需要的PTE。

### Linux虚拟内存结构

![image-20200311102850927](虚拟内存.assets/image-20200311102850927.png)

1. Linux中所有进程的虚拟内存地址都是从0x00400000开始的
2. VM中分成两个部分：当前进程的虚拟内存，储存着用户的代码和数据，地址的前12位是0，内核的虚拟内存，存储着内核的代码和数据，地址前12位是1。
3. 用户区和内核区中间有间隙，没有画出来
4. 内核部分：分为每个进程共享的内核数据和代码，以及该进程独有的数据（比如page table一级页表表头，mm_struct：将用户区分成不同的area），即该进程的上下文。

### Linux将虚拟内存分区域管理

在Kernal的task_struct区域，存储着该进程的上下文，其中pdg：指向该进程的一级页表表头，mmap:存储着各区域的信息，见下图：

![image-20200311103550340](虚拟内存.assets/image-20200311103550340.png)

其中：mmap是指向vm_area_struct的链表（or红黑树）,struct中存储着某一区域的信息，比如区域的范围，区域的读写权限，区域是共享还是独有。

### Linux内核处理缺页中断

当MMU没有找到有效的PTE后，会发出缺页中断，控制权交给kernal，kernal的处理方式分为三种：

1. 查找该VA是否在area，如果不在，说明不存在所需的page。
2. 如果VA指向的是area区域，但是该区域的权限不足，也发出protection exception
3. 常见的缺页中断是：当前VA是在合理的aera，只是uncached（没有缓存到PM），此时从磁盘取出所需page到PM即可。

![image-20200311104401800](虚拟内存.assets/image-20200311104401800.png)



## 内存隐射

### 定义

内存映射是指：Linux内核通过将虚拟内存区域与磁盘上的对象关联起来，以初始化这个虚拟内存区域的内容，这个过程称为内存映射。内存映射根据对象的不同，可以分为两种：

1. Linux文件系统中的普通文件：将VM中的area和普通的磁盘文件映射，实现area的初始化，但是这些VP并没有进入到PM中，按需调度即可。
2. 匿名文件：由内核创建，表示这个area已经被映射，但是也不存在于PM或者任何地方，只有当需要调用此VP时，内核在PM中牺牲掉合适的PP，然后用这个VP覆盖，此时PM中的这个页面，全部为0。（此过程PM和磁盘没有数据传输），所以这些被映射到匿名文件的VP，有时候也叫做demanding-zero page/请求二进制零的页。这些VP被初始化后，会在内核专门维护的swap file/交换文件（也称为交换空间或者交换区域）中换来换去。

### 共享对象

![image-20200311114847232](虚拟内存.assets/image-20200311114847232.png)

可以发现：两个进程的不同段的虚拟地址，被映射到了相同的object（共享对象）

### 私有的写时复制对象

![image-20200311115110351](虚拟内存.assets/image-20200311115110351.png)

可以发现：两个进程被映射到同一个object，但是这个object是**私有写时复制（COW）**的，而对应的PTE也被**标记为只读**，如果不进行写操作，这个对象可以看成共享对象，但是有进程要改写该对象时，会复制一段新的对象出来：

![image-20200311143908449](虚拟内存.assets/image-20200311143908449.png)

可以发现：当试图对private COW对象进行写操作，会触发protection fault，此后内核会复制出一段可供写的代码段，并对process 2进行重新映射。

### Fork函数

VM以及内存映射机制，解释了为什么进行fork，可以得到私有的地址空间，并不会占用太多的内存资源。

**为新进程创建VM的步骤**

1. 从父进程中复制相同的mm_strcut，vm_area_struct和页表
2. 页面都被标记成只读
3. 每个area都被标记为private COW。

这样子进程和父进程的VM和objects完全相同，如果不进行写操作，则共享对象，如果写操作，则复制后再写（copy on write）

### execve函数

通过execve函数，可以在原有的进程中加载新程序，具体过程如下：

1. 释放原来的page table和vm_area_struct。
2. 加载.out文件，进行area的映射，从而创建了新的页表和vm_area_struct，创建规则见下图
3. 为VM建立映射后，PC开始逐条执行语句，按需将VP加载到PP。

![image-20200311151037698](虚拟内存.assets/image-20200311151037698.png)

可以发现：映射分成两种：一种是file-backed，一种是damand-zero

#### 用户级内存映射

使用系统函数mmap，可以在VM空间指定一段长度，对目标文件fd的offset位置开始，进行映射，当flags被设置为MAP_ANON，则进行demand-zero映射。

![image-20200311154058485](虚拟内存.assets/image-20200311154058485.png)

注意：start为Kernal进行映射的VM起始地址，但只是我们的Hint，如果start部分不能进行映射，则返回的是kernal自己决定的映射起始地址。

注意：仅仅是映射！没有任何实际数据的复制！只有我们读取该VA处数据时，才会将文件中的地址加载到PM中

**举例**

![image-20200311154924348](虚拟内存.assets/image-20200311154924348.png)

通过mmap，直接把**file中的文件映射到了VM的bufp地址处**，然后再写入stdout。（不需要读取）